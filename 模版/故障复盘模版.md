<div align='center' ><font size='70'>{故障标题，例：2021-05-21 xxx服务不可用导致xx页面白屏}</font></div> 

# 术语表（可选）

| 字面   | 释义  | 相关链接或其他注解  |
|------| ----  | ----  |
|  TSG | Troubleshooting Guide，或排障指南 | |  
| ...  | ...  | ...  |

# 故障背景知识（可选）
解释需要理解事故的所有背景知识，链接相关的设计文档和代码库。

# 故障简述（必须）
简要描述这是一起由什么原因导致的一起什么类型的故障，造成的影响有哪些？

# 相关处理人（必须）
* 值班工程师：
* 故障处理人员：
* 复盘组织者：
* 其他相关人员（产品、运营、数据分析、客服人员等等）：

# 故障影响
| 影响维度 | 	影响详情                                             |
| ---- |---------------------------------------------------|
|SLA影响 | 	故障影响SLA的详细情况                                     |
|业务影响 | 	用户侧影响表现描述、故障期间影响用户占比（影响用户量/故障期间大盘用户量）            |
| 用户反馈 | 业务自有反馈渠道+客服统计量，有多个终端需合计，用户ID去重，去除非故障相关，去除无故障同期反馈量 |
| 收入影响	| 评估故障影响的收入规模| 
| 舆论影响	|（公关侧评估）微博讨论/热搜榜位次和在榜时间；媒体报道情况；评论和报道反映的舆论倾向性情况(正面、负面、中立）；舆情处理时效情况；总结并整体评价 |
| 其他事故维度（针对事故复盘）|	其他纬度如有则补充，如业务指标影响、Push消息推送、个人信息保护、支付、用户/业务数据丢失、系统/网络安全/业务安全、法律纠纷、业务处罚|

# 故障时间线（必须）
2021-11-03：
* 17:40  问题引入，查询引擎对于产品大盘需求中的部分指标不适配，因此引擎开发同学，对引擎做了兼容修改；
* 19:00  问题引入，灰度发布后回归测试验证无误，执行全量发布

2021-11-04：
* 03:50 故障发现，值班同学收到任务执行情况电话告警，MySQL异常告警
* 03:51 响应处理，处理过程中发现任务大量执行失败，MySQL主库和从库CPU负载异常，从库开始出现同步延迟，
* 04:10 响应处理，尝试联系DBA,联系不上
* 05:00 响应处理，排查到两个慢SQL，然后将用于执行该SQL的指标进行了下线，避免再次出现慢SQL
* 05:22 响应处理，继续尝试重跑任务
* 06:30 响应处理，通过观察任务执行情况，发现任务处理时长超出预期，MySQL主从的CPU和慢查询依旧没有降低的趋势
* 07:00 响应处理，通过查询指标预计算监控发现，主要慢的指标计算任务都是关于缺陷数据域的
* 07:20 止损开始，将缺陷数据域的所有指标计算任务暂时下线，不进行预计算，并尝试重新执行遗留的数据域和预计算任务
* 08:00 止损生效，经过一段时间观察，任务执行速度和结果符合预期
* 08:30 故障处理，首页发布公告
* 11:40 故障处理，分析出故障根因，回滚代码，重新将BUG指标上线
* 12:00 故障处理，重跑BUG任务，恢复BUG数据
* 14:00 故障结束，数据完全恢复

# 故障触发条件（必须）
描述故障的触发条件是什么，是否可以按步骤重现？如是，请描述条件和步骤

# 故障根因（必须）
详细描述故障的根因，要挖掘的足够深入，如果是bug引入类型要把代码diff附加上，如果是上线导致需要详细附加时间点监控图表。

# 解决方案（必须）
## 临时解决方案
描述如何可以快速修复和处理，即便是临时的方案
## 根本解决方案
描述如何可以根本修复和避免这个问题

# 主要环节分析（可选）
## 需求阶段
1.需求是否通过需求评审。无则说明。
2.是否有需求逻辑有误、需求描述不清晰等问题。有则说明
## 技术/架构设计阶段
1.是否有技术/架构评审。无则说明
2.是否有服务降级、容灾容错、影响评估不完善等技术设计问题。有则说明
## 开发阶段
1.是否存在编码不严谨、不符合技术设计要求、配置不当等问题？有则说明
2.是否可以单测覆盖？是否。无则说明。
3.是否有代码评审？是否。无则说明。
4.在提交代码前是否有相应的质量检查，如编译/单元测试，代码规范检查，安全检查等。是否。无则说明
## 测试阶段
1.能否可在测试阶段发现问题，是否。无则说明。
2.测试阶段事故可拦截手段：xx、xx、xx
3.是否可以通过数据监控发现：是否。无则说明。
## 持续集成
1.代码提交后是否有相应的质量检查，如编译/单元测试，代码规范检查，安全检查等？是否有质量红线？质量红线设置是否足够？是否。无则说明
2.代码提交后是否进行代码评审？是否。无则说明
3.在构建生成制品后是否有相应质量检查，如BVT测试、冒烟测试等。
## 线上发布或变更阶段
1.发布开始和结束时间
2.发布方式：代码发布、配置变更、客户端发布、数据流变更、其他
3.能否可在发布阶段发现问题？是否。无则说明。
4.发布阶段事故可拦截手段：灰度、监控
5.是否有标准化、稳定的环境来验证制品：是否。无则说明
6.是否有发布规范：是否。有则填写发布规范，无则说明
7.发布的审批人（如果有的话）是否有足够的信息来作出发布的决策
8.是否有金丝雀发布、灰度发布、发布质量监控、发布后验证等相应措施？是否。无则说明。
## 运营维护
1.SLI和SLO是否合理且完备 
2.是否由于对容量缺乏预测、依赖服务、环境变化未及时处理等导致故障被引入？
## 故障发现
1.故障开始时间
2.发现时间
3.是否能更快定位原因？无则说明。
4.Detect是否可以先于用户反馈发现问题？无则说明。
5.发现方式：监控、内部反馈、用户/客户/商户反馈、其他
6.有无告警：有无，有的话，需要填写告警时间、级别、title
7.是否有故障处理手册/标准操作指引，有则填写具体文件，无则说明
## 处理环节
1.是否可以通过SOP快速响应？有无，有的话需要填写地址；无则说明。
2.初步止损时间
3.初步止损方式：回滚、降级、扩容、关闭实验开关、HOTFIX代码、重跑任务、其他
4.最终止损时间
5.最终止损方式：回滚、降级、扩容、关闭实验开关、HOTFIX代码、重跑任务、其他
6.能否更快一些止损和恢复？无则说明。
7.程序实现上能否拦截？无则说明。
8.测试和检查能否拦截？无则说明。
9.发布过程能否拦截？无则说明。
10.操作如何出问题的？
11.流程上哪里有问题？
12.容量上是否有问题？
13.第三方依赖是否有问题？
14.数据中心网络设备上是否有问题？
15.配置管理上有没有问题？
16.有没有共性问题？

# 经验教训
## 故障处理过程中可以借鉴的地方 - GOOD
1.参考错误码设计{链接}，报警没有误报且没有泛滥，指标足够详细。
2.根据SOP{链接}，oncall同学响应及时且首先止损。
3.按照TSG中准确表示的排障步骤{链接}，xx同学在短时间内快速定位问题根因。
## 故障处理过程中需要避免的错误 - BAD
1.没有阅读故障处理预案导致故障持续时间较长。{跟进项序号}
2.日志只存留于容器中，在代码回滚时造成日志丢失并影响排查过程。{跟进项序号}
## 故障处理过程中发现的其他知识 - LUCKY
1.发现可以使用XX工具{链接}减少查询日志的时间。

# 跟进措施
改进类型 选择以下几类其中一类：
* 调研：如果故障恢复后还有我们需要进一步深入了解的系统行为或者影响，则用这个分类。
* 缓解：如果在故障处理流程中有可以减轻故障影响范围，或者缩短故障影响时间的优化测试，则用这个分类。
* 修复：如果在故障后系统中还有需要修复的事项已彻底杜绝/避免故障，则用这个分类。
* 长期方案：如果可以从根源上杜绝/避免这个故障发生的优化措施但需要长期的投入，则用这个分类。
* 过程改进：如果发现此类故障的杜绝/避免需要过程制度上的优化或调整，则用这个分类。
* 监控：如果发现此类故障排查需要更多上下文支撑，包括指标（metrics）、日志（logs）或追踪记录（traces），则用这个分类。


| 序号  | 改进类型    | 改进措施    | 跟进人    |  验收人   |  预期完成时间   |  当前状态   |
|-----|-----|-----|-----|-----|-----|-----|
| 1   |  监控   |  增加监控   |     |     |     |     |
| 2   |  长期方案   |  方案描述   |     |     |     |     |

# 附录
* 其他上下文或相关故障链接
* 技术设计文档、产品文档、数据报表文档、监控平台地址、用户反馈数据等链接
* 故障相关联的需求链接(
* 故障相关联的发布变更项(发布变更对应的链接)
